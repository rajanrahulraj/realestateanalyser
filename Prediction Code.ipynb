{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059e56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56d195",
   "metadata": {},
   "source": [
    "## Part A: Predicting Area Traffic and Business Activity using Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a4a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a dataset\n",
    "data = pd.read_csv('2020-2021month.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b9b04",
   "metadata": {},
   "source": [
    "- #### User Input Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d8417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start time of the forecast and the number of months of the forecast\n",
    "# The user can enter\n",
    "location_id = 4\n",
    "start_time = pd.to_datetime('2023-12-01')\n",
    "num_months = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93ffd2",
   "metadata": {},
   "source": [
    "####  Drop_Off count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa8e1d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for LocationID 4 from 2023-12-01 00:00:00 to 2024-03-01 00:00:00:\n",
      "2023-12-01 00:00:00: 13271.823352004822\n",
      "2024-01-01 00:00:00: 13493.18042524825\n",
      "2024-02-01 00:00:00: 13975.820082990753\n"
     ]
    }
   ],
   "source": [
    "with open('model_DO.pkl', 'rb') as f:\n",
    "    models = pickle.load(f)\n",
    "\n",
    "# Get the model corresponding to the LocationID\n",
    "model = models[location_id]\n",
    "\n",
    "# Get the historical data needed for the model, either training data or other historical data\n",
    "# In this example, we use the training data as historical data\n",
    "location_data = data[data['LocationID'] == location_id]\n",
    "historical_data = location_data['DropOff_count'].values\n",
    "\n",
    "# Calculate the end of the forecast based on the start of the forecast and the number of months in the forecast\n",
    "end_time = start_time + pd.DateOffset(months=num_months)\n",
    "\n",
    "# Use the model to make predictions and get future data\n",
    "predictions_DO = model.predict(start=len(historical_data), end=len(historical_data) + num_months - 1)\n",
    "\n",
    "# Print prediction results\n",
    "print(f'Predictions for LocationID {location_id} from {start_time} to {end_time}:')\n",
    "for i, prediction in enumerate(predictions_DO):\n",
    "    prediction_date = start_time + pd.DateOffset(months=i)\n",
    "    print(f'{prediction_date}: {prediction}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71505199",
   "metadata": {},
   "source": [
    "#### Pick_UP count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40efc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for LocationID 4 from 2023-12-01 00:00:00 to 2024-03-01 00:00:00:\n",
      "2023-12-01 00:00:00: 3121.4483169757746\n",
      "2024-01-01 00:00:00: 2959.856103029276\n",
      "2024-02-01 00:00:00: 2877.354792466138\n"
     ]
    }
   ],
   "source": [
    "with open('model_PU.pkl', 'rb') as f:\n",
    "    models = pickle.load(f)\n",
    "\n",
    "# Get the model corresponding to the LocationID\n",
    "model = models[location_id]\n",
    "\n",
    "# Get the historical data needed for the model, either training data or other historical data\n",
    "# In this example, we use the training data as historical data\n",
    "location_data = data[data['LocationID'] == location_id]\n",
    "historical_data = location_data['PickUp_count'].values\n",
    "\n",
    "# Calculate the end of the forecast based on the start of the forecast and the number of months in the forecast\n",
    "end_time = start_time + pd.DateOffset(months=num_months)\n",
    "\n",
    "# Use the model to make predictions and get future data\n",
    "predictions_PU = model.predict(start=len(historical_data), end=len(historical_data) + num_months - 1)\n",
    "\n",
    "times = []\n",
    "# Print prediction results\n",
    "print(f'Predictions for LocationID {location_id} from {start_time} to {end_time}:')\n",
    "for i, prediction in enumerate(predictions_PU):\n",
    "    prediction_date = start_time + pd.DateOffset(months=i)\n",
    "    times.append(prediction_date)\n",
    "    print(f'{prediction_date}: {prediction}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32100bfa",
   "metadata": {},
   "source": [
    "#### Use the predicted values above to determine the number of passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e6e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 'passenger' values for LocationID 4 for years [Timestamp('2023-12-01 00:00:00'), Timestamp('2024-01-01 00:00:00'), Timestamp('2024-02-01 00:00:00')] : [13544.00801531 11634.87827421 11165.56697285]\n"
     ]
    }
   ],
   "source": [
    "# Load the trained models from the .pkl file\n",
    "with open('models_Passenger.pkl', 'rb') as f:\n",
    "    models_dict = pickle.load(f)\n",
    "\n",
    "# Get the model for the selected LocationID from the models_dict\n",
    "model_for_location = models_dict[location_id]\n",
    "\n",
    "# Prepare the exogenous features for prediction (future values of DropOff_count and PickUp_count)\n",
    "future_times = times\n",
    "future_features = pd.DataFrame({'DropOff_count': predictions_DO,  # Replace with the desired future values\n",
    "                                'PickUp_count': predictions_PU})    # Replace with the desired future values\n",
    "\n",
    "# Make predictions for the future years using the ARIMA model\n",
    "predictions = model_for_location.predict(start=len(future_features), end=len(future_features) + len(future_times) - 1,\n",
    "                                         exog=future_features)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Predicted 'passenger' values for LocationID\", location_id, \"for years\", future_times, \":\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d8d12",
   "metadata": {},
   "source": [
    "## Part B: Forecasting the Overall Trend of Real Estate Prices using Linear Features of Real Estate Total Value:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43180f6",
   "metadata": {},
   "source": [
    "- #### User Input Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea362e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = [2023, 2024, 2025]\n",
    "location_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b597fda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted FULLVAL for LocationID 4 in year 2023: 3527604623.666687\n",
      "Growth Rate for LocationID 4 in year 2023: 0.00%\n",
      "\n",
      "Predicted FULLVAL for LocationID 4 in year 2024: 3699292684.5\n",
      "Growth Rate for LocationID 4 in year 2024: 4.87%\n",
      "\n",
      "Predicted FULLVAL for LocationID 4 in year 2025: 3870980745.333313\n",
      "Growth Rate for LocationID 4 in year 2025: 9.73%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the models from the .pkl file\n",
    "with open('models_RealEstate.pkl', 'rb') as f:\n",
    "    models_dict = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Get the model for the specific LocationID\n",
    "model_for_location = models_dict[location_id]\n",
    "\n",
    "# Define the future years for which you want to make predictions\n",
    "future_years = np.array(year).reshape(-1, 1)\n",
    "\n",
    "# Make predictions for the future years\n",
    "predictions = model_for_location.predict(future_years)\n",
    "\n",
    "# Get the most recent 'FULLVAL' value for the given LocationID\n",
    "most_recent_fullval = model_for_location.predict(future_years[0].reshape(-1, 1))\n",
    "\n",
    "# Calculate the growth rate as a percentage\n",
    "growth_rate = ((predictions - most_recent_fullval) / most_recent_fullval) * 100\n",
    "\n",
    "# Print the predictions and growth rate\n",
    "for i, year in enumerate(future_years.flatten()):\n",
    "    print(f\"Predicted FULLVAL for LocationID {location_id} in year {year}: {predictions[i]}\")\n",
    "    print(f\"Growth Rate for LocationID {location_id} in year {year}: {growth_rate[i]:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75286535",
   "metadata": {},
   "source": [
    "## PartC. Understanding the Impact of Different Variables on Real Estate Prices through OLS Regression Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2493e",
   "metadata": {},
   "source": [
    "- #### User Input Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682bd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start time of the forecast and the number of months of the forecast\n",
    "# The user can enter\n",
    "location_id = 4\n",
    "start_time = pd.to_datetime('2024-7-01')\n",
    "num_months = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c17670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the model\n",
    "with open('Ensembling.pkl', 'rb') as f:\n",
    "    models_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b80875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_dict = models_dict['DO']\n",
    "PU_dict = models_dict['PU']\n",
    "Pa_dict = models_dict['Pa']\n",
    "fare_dict = models_dict['fare']\n",
    "DOP_dict = models_dict['DOP']\n",
    "coef_dict = models_dict['coef']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e7e9a",
   "metadata": {},
   "source": [
    "- Predicted required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d70cd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for LocationID 4 from 2024-07-01 00:00:00 to 2025-07-01 00:00:00:\n",
      "2024-07-01 00:00:00: 13271.823352004822\n",
      "2024-08-01 00:00:00: 13493.18042524825\n",
      "2024-09-01 00:00:00: 13975.820082990753\n",
      "2024-10-01 00:00:00: 14319.421730693837\n",
      "2024-11-01 00:00:00: 14736.59824990118\n",
      "2024-12-01 00:00:00: 15114.42973584186\n",
      "2025-01-01 00:00:00: 15512.888773795103\n",
      "2025-02-01 00:00:00: 15900.123670812667\n",
      "2025-03-01 00:00:00: 16293.051179905018\n",
      "2025-04-01 00:00:00: 16682.68682866883\n",
      "2025-05-01 00:00:00: 17073.80244676684\n",
      "2025-06-01 00:00:00: 17463.863806111556\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('2020-2021month.csv')\n",
    "\n",
    "# DropOff_count\n",
    "\n",
    "# Get the historical data needed for the model, either training data or other historical data\n",
    "# In this example, we use the training data as historical data\n",
    "location_data = data[data['LocationID'] == location_id]\n",
    "historical_data = location_data['DropOff_count'].values\n",
    "\n",
    "# Calculate the end of the forecast based on the start of the forecast and the number of months in the forecast\n",
    "end_time = start_time + pd.DateOffset(months=num_months)\n",
    "\n",
    "# Use the model to make predictions and get future data\n",
    "predictions_DO = DO_dict[location_id].predict(start=len(historical_data), end=len(historical_data) + num_months - 1)\n",
    "\n",
    "# PickUp_count\n",
    "\n",
    "historical_data = location_data['PickUp_count'].values\n",
    "\n",
    "# Use the model to make predictions and get future data\n",
    "predictions_PU = PU_dict[location_id].predict(start=len(historical_data), end=len(historical_data) + num_months - 1)\n",
    "\n",
    "future_times = []\n",
    "print(f'Predictions for LocationID {location_id} from {start_time} to {end_time}:')\n",
    "for i, prediction in enumerate(predictions_DO):\n",
    "    prediction_date = start_time + pd.DateOffset(months=i)\n",
    "    future_times.append(prediction_date)\n",
    "    print(f'{prediction_date}: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b35bd191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passenger\n",
    "\n",
    "# Prepare the exogenous features for prediction (future values of DropOff_count and PickUp_count)\n",
    "future_features = pd.DataFrame({'DropOff_count': predictions_DO,  # Replace with the desired future values\n",
    "                                'PickUp_count': predictions_PU})    # Replace with the desired future values\n",
    "\n",
    "# Make predictions for the future years using the ARIMA model\n",
    "prediction_Pa = Pa_dict[location_id].predict(start=0, end=len(future_times)- 1,\n",
    "                                         exog=future_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f69d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare\n",
    "\n",
    "\n",
    "# Prepare the exogenous features for prediction (future values of DropOff_count and PickUp_count)\n",
    "future_features = pd.DataFrame({'passenger': prediction_Pa,  # Replace with the desired future values\n",
    "                                'DropOff_count': predictions_DO})    # Replace with the desired future values\n",
    "\n",
    "# Make predictions for the future years using the ARIMA model\n",
    "prediction_fare = fare_dict[location_id].predict(start=0, end=len(future_times)- 1,\n",
    "                                         exog=future_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b595420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO_passenger\n",
    "\n",
    "\n",
    "# Prepare the exogenous features for prediction (future values of DropOff_count and PickUp_count)\n",
    "future_features = pd.DataFrame({'passenger': prediction_Pa,  # Replace with the desired future values\n",
    "                                'DropOff_count': predictions_DO})    # Replace with the desired future values\n",
    "\n",
    "# Make predictions for the future years using the ARIMA model\n",
    "prediction_DOP = DOP_dict[location_id].predict(start=0, end=len(future_times)- 1,\n",
    "                                         exog=future_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23903d57",
   "metadata": {},
   "source": [
    "- Read data for the year 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7eb6220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "filtered_data = data[(data['Date'].dt.year == 2021) & (data['LocationID'] == location_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066e06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger = filtered_data['PU_passenger'].sum() + filtered_data['DO_passenger'].sum()\n",
    "fare = filtered_data['PU_fare'].sum() + filtered_data['DO_fare'].sum()\n",
    "DO_passenger = filtered_data['DO_passenger'].sum()\n",
    "DropOff_count = filtered_data['DropOff_count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13338ae",
   "metadata": {},
   "source": [
    "- To view the coefficient data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f2c6eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const                0.668977\n",
      "passenger       -11448.001369\n",
      "fare             -2914.884336\n",
      "DO_passenger     29514.906651\n",
      "DropOff_count    34397.668224\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(coef_dict[location_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d014218",
   "metadata": {},
   "source": [
    "- The impact of taxi data on real estate is positive if the Influence_Factor is positive and negative if the Influence_Factor is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f475198",
   "metadata": {},
   "outputs": [],
   "source": [
    "Influence_Factor = ((np.sum(prediction_Pa) - passenger) / passenger) * coef_dict[location_id][1] + \\\n",
    "      ((np.sum(prediction_fare) - fare) / fare) * coef_dict[location_id][2] + \\\n",
    "      ((np.sum(prediction_DOP) - DO_passenger) / DO_passenger) * coef_dict[location_id][3] + \\\n",
    "      ((np.sum(predictions_DO) - DropOff_count) / DropOff_count) * coef_dict[location_id][4] + \\\n",
    "      coef_dict[location_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9762adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88464.72141419831\n"
     ]
    }
   ],
   "source": [
    "print(Influence_Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159f2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
