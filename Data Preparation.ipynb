{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "025fcaac",
   "metadata": {},
   "source": [
    "# Part 1: Data Source\n",
    "### Summary of datasets:\n",
    "| Name                                |    Data   Source                  | Source                                      |\n",
    "|----------------------------------------|--------------------------------------|--------------------------------------------------------|\n",
    "|     Taxi_Zones                           |   https://data.cityofnewyork.us/Transportation/NYC-Taxi-Zones/d3c5-ddgc                                |      NYC Open Data                                   |\n",
    "|     Property Valuation and Assessment Data              |    https://data.cityofnewyork.us/City-Government/Property-Valuation-and-Assessment-Data/yjxr-fw8i                                |     NYC Open Data                                                  |\n",
    "|     2015-2020 Yellow Taxi Trip Deta              |      https://data.cityofnewyork.us/browse?q=taxi&sortBy=relevance                                |     NYC Open Data                                                  |\n",
    "|     School Dataset - USA Public School                    |     https://www.kaggle.com/datasets/carlosaguayo/usa-public-schools       |       Kaggle                                |\n",
    "|     Hospitals Dataset - USA Hospitals                      |     https://www.kaggle.com/datasets/carlosaguayo/usa-hospitals                                |     Kaggle                                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b84d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import mysql.connector\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1245d799",
   "metadata": {},
   "source": [
    "# Part 2: Data pre-processing\n",
    "\n",
    "### 2.1 Taxi Zones Deta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c1d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataSource/taxi_zones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3494b7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>the_geom</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>MULTIPOLYGON (((-74.18445299999996 40.69499599...</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>MULTIPOLYGON (((-73.82337597260663 40.63898704...</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>MULTIPOLYGON (((-73.84792614099985 40.87134223...</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>MULTIPOLYGON (((-73.97177410965318 40.72582128...</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>MULTIPOLYGON (((-74.17421738099989 40.56256808...</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  Shape_Leng                                           the_geom  \\\n",
       "0         1    0.116357  MULTIPOLYGON (((-74.18445299999996 40.69499599...   \n",
       "1         2    0.433470  MULTIPOLYGON (((-73.82337597260663 40.63898704...   \n",
       "2         3    0.084341  MULTIPOLYGON (((-73.84792614099985 40.87134223...   \n",
       "3         4    0.043567  MULTIPOLYGON (((-73.97177410965318 40.72582128...   \n",
       "4         5    0.092146  MULTIPOLYGON (((-74.17421738099989 40.56256808...   \n",
       "\n",
       "   Shape_Area                     zone  LocationID        borough  \n",
       "0    0.000782           Newark Airport           1            EWR  \n",
       "1    0.004866              Jamaica Bay           2         Queens  \n",
       "2    0.000314  Allerton/Pelham Gardens           3          Bronx  \n",
       "3    0.000112            Alphabet City           4      Manhattan  \n",
       "4    0.000498            Arden Heights           5  Staten Island  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d03de76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a6f95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OBJECTID        int64\n",
       "Shape_Leng    float64\n",
       "the_geom       object\n",
       "Shape_Area    float64\n",
       "zone           object\n",
       "LocationID      int64\n",
       "borough        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3436f221",
   "metadata": {},
   "source": [
    "- Filter relevant information outside of Manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad199c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['borough'] == 'Manhattan']\n",
    "filtered_df.to_csv('programing data/taxi_zones.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abf5a0",
   "metadata": {},
   "source": [
    "- Saveing the data to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MySQL database connection\n",
    "conn = mysql.connector.connect(host='localhost', user='root', password='147258Xiao', database='Investment')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE Zones (\n",
    "    OBJECTID INT,\n",
    "    Shape_Leng FLOAT,\n",
    "    The_geom GEOMETRY,\n",
    "    Shape_Area FLOAT,\n",
    "    Zone VARCHAR(255),\n",
    "    LocationID INT,\n",
    "    borough VARCHAR(255)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_table_sql)\n",
    "\n",
    "with open('programing data/taxi_zones.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row\n",
    "    for row in reader:\n",
    "        object_id = int(row[0])\n",
    "        shape_length = float(row[1])\n",
    "        geom = row[2]  # The MULTIPOLYGON data as a string representation\n",
    "        shape_area = float(row[3])\n",
    "        zone = row[4]\n",
    "        location_id = int(row[5])\n",
    "        borough = row[6]\n",
    "\n",
    "        # Insert data into the table\n",
    "        insert_sql = \"INSERT INTO Zones (OBJECTID, Shape_Leng, the_geom, Shape_Area, zone, LocationID, borough) VALUES (%s, %s, ST_GeomFromText(%s), %s, %s, %s, %s)\"\n",
    "        cursor.execute(insert_sql, (object_id, shape_length, geom, shape_area, zone, location_id, borough))\n",
    "        conn.commit()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09324e4a",
   "metadata": {},
   "source": [
    "### 2.2 Property Valuation and Assessment Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117a5e0",
   "metadata": {},
   "source": [
    "#### Explain the meaning of each feature\n",
    "\n",
    "- BBLE: It is a New York City real estate identification number.\n",
    "- BORO: 1: Manhattan\n",
    "- Block: Block number, representing the integer value of the block in which the property is located.\n",
    "- LOT (Lot) : Lot number, indicating the integer value of the lot in which the property is located.\n",
    "- EASEMENT: Land use right, which denotes the use right or restriction of land ownership.\n",
    "- OWNER:Building owner.\n",
    "- BLDGCL: Represents the class or building use code of a building\n",
    "- TAXCLASS: Tax classification code, a string code used to identify the tax classification of the real estate.\n",
    "- LTFRONT: The width of the lot in front of the real estate, expressed as an integer value in feet.\n",
    "- LTDEPTH: The depth of a real estate plot, expressed as an integer value in feet.\n",
    "- EXT: Extended information, which may be additional descriptions or features related to buildings or land.\n",
    "- STORIES: The number of floors of the building\n",
    "- FULLVAL: The full value of real estate, expressed as an integer value in US dollars.\n",
    "- AVLAND: Land value, expressed as an integer value in US dollars.\n",
    "- AVTOT: Total value, expressed as an integer value in US dollars.\n",
    "- EXALND: Tax free land value, expressed as an integer value in US dollars.\n",
    "- EXTOT: Total tax exemption value, expressed as an integer value in US dollars.\n",
    "- EXCD1: Tax exemption class code (first assessment), a string code used to identify the tax exemption class.\n",
    "- STADDR: Street address, a string representing the specific street address of the real estate.\n",
    "- POSTCODE: Postal code denotes the postal code of the location of the real estate\n",
    "- EXMPTCL: This is the tax exemption classification code used to identify the tax exemption category to which the property belongs.\n",
    "- BLDFRONT: Width of the front of the building, expressed as an integer value in feet.\n",
    "- BLDDEPTH: The depth of a building, expressed as an integer value in feet.\n",
    "- AVLAND2: The total value of the second assessment, expressed as a floating point value in US dollars.\n",
    "- AVTOT2: The total value of the second assessment, expressed as a floating point value in US dollars.\n",
    "- EXLAND2: Tax land value (second assessment), expressed as a floating point value in US dollars.\n",
    "- EXTOT2: Total duty-free value (second assessment), expressed as floating point value in US dollars.\n",
    "- EXCD2 : Tax exemption class code (second assessment), a string code used to identify the tax exemption class.\n",
    "- PERIOD : The time period in which the data was recorded, a string representing the time period in which the data was recorded.\n",
    "- YEAR: Year of the data record, a string indicating the year of the record.\n",
    "- VALTYPE: The value type of the data record, a string indicating the value type of the record.\n",
    "- Borough: The administrative division in which the immovable property is located, a string indicating the administrative division.\n",
    "- Latitude: The latitude of the real estate represents the latitude value expressed as a floating point value.\n",
    "- Longitude: The longitude of real property, which represents the longitude value expressed as a floating point value.\n",
    "- Community Board: Community board, denoting the administrative division unit of the district\n",
    "- Council District: City Council District, which represents the division of the district in the city Council.\n",
    "- Census Tract: Census area, which represents the division of the area in the census.\n",
    "- BIN: The real property identification number, similar to the BBLE column, is used to uniquely identify each real property as a floating point value\n",
    "- NTA: Community ID, a string indicating the community.\n",
    "- New Georeferenced Column: New georeferenced column, a string column representing georeferenced information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e124bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataSource/Property_Valuation_and_Assessment_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80368871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBLE</th>\n",
       "      <th>BORO</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>EASEMENT</th>\n",
       "      <th>OWNER</th>\n",
       "      <th>BLDGCL</th>\n",
       "      <th>TAXCLASS</th>\n",
       "      <th>LTFRONT</th>\n",
       "      <th>LTDEPTH</th>\n",
       "      <th>...</th>\n",
       "      <th>VALTYPE</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Community Board</th>\n",
       "      <th>Council District</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>BIN</th>\n",
       "      <th>NTA</th>\n",
       "      <th>New Georeferenced Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000163859</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEN, QI TOM</td>\n",
       "      <td>R4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>AC-TR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000730028</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYC DSBS</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>AC-TR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000730029</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYC DSBS</td>\n",
       "      <td>Y7</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>500</td>\n",
       "      <td>...</td>\n",
       "      <td>AC-TR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000297504</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>7504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>AC-TR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000360012</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYC DSBS</td>\n",
       "      <td>Y7</td>\n",
       "      <td>4</td>\n",
       "      <td>534</td>\n",
       "      <td>604</td>\n",
       "      <td>...</td>\n",
       "      <td>AC-TR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BBLE  BORO  BLOCK   LOT EASEMENT         OWNER BLDGCL TAXCLASS  \\\n",
       "0  1000163859     1     16  3859      NaN  CHEN, QI TOM     R4        2   \n",
       "1  1000730028     1     73    28      NaN      NYC DSBS     V1        4   \n",
       "2  1000730029     1     73    29      NaN      NYC DSBS     Y7        4   \n",
       "3  1000297504     1     29  7504      NaN           NaN     R0        2   \n",
       "4  1000360012     1     36    12      NaN      NYC DSBS     Y7        4   \n",
       "\n",
       "   LTFRONT  LTDEPTH  ... VALTYPE  Borough  Latitude  Longitude  \\\n",
       "0        0        0  ...   AC-TR      NaN       NaN        NaN   \n",
       "1      183       52  ...   AC-TR      NaN       NaN        NaN   \n",
       "2       90      500  ...   AC-TR      NaN       NaN        NaN   \n",
       "3       36       73  ...   AC-TR      NaN       NaN        NaN   \n",
       "4      534      604  ...   AC-TR      NaN       NaN        NaN   \n",
       "\n",
       "   Community Board  Council District  Census Tract  BIN  NTA  \\\n",
       "0              NaN               NaN           NaN  NaN  NaN   \n",
       "1              NaN               NaN           NaN  NaN  NaN   \n",
       "2              NaN               NaN           NaN  NaN  NaN   \n",
       "3              NaN               NaN           NaN  NaN  NaN   \n",
       "4              NaN               NaN           NaN  NaN  NaN   \n",
       "\n",
       "   New Georeferenced Column  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "3                       NaN  \n",
       "4                       NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c283cf17",
   "metadata": {},
   "source": [
    "- Check how many rows and columns dataset has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a62277ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9845857, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bcfe31",
   "metadata": {},
   "source": [
    "- Check if there are duplicate rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d63661ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BBLE', 'BORO', 'BLOCK', 'LOT', 'EASEMENT', 'OWNER', 'BLDGCL',\n",
       "       'TAXCLASS', 'LTFRONT', 'LTDEPTH', 'EXT', 'STORIES', 'FULLVAL', 'AVLAND',\n",
       "       'AVTOT', 'EXLAND', 'EXTOT', 'EXCD1', 'STADDR', 'POSTCODE', 'EXMPTCL',\n",
       "       'BLDFRONT', 'BLDDEPTH', 'AVLAND2', 'AVTOT2', 'EXLAND2', 'EXTOT2',\n",
       "       'EXCD2', 'PERIOD', 'YEAR', 'VALTYPE', 'Borough', 'Latitude',\n",
       "       'Longitude', 'CommunityBoard', 'CouncilDistrict', 'CensusTract', 'BIN',\n",
       "       'NTA', 'NewGeoreferencedColumn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove whitespace in or around feature names\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "#check to ensure whitespaces have been removed\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588c5134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate (excluding first) rows in the table is:  0\n",
      "Number of duplicate rows (including first) in the table is: 0\n"
     ]
    }
   ],
   "source": [
    "#check for duplicate rows\n",
    "\n",
    "#Print the number of duplicates, without the original rows that were duplicated\n",
    "print('Number of duplicate (excluding first) rows in the table is: ', df.duplicated().sum())\n",
    "\n",
    "# Use \"keep=False\" to mark all duplicates as true, including the original rows that were duplicated.\n",
    "print('Number of duplicate rows (including first) in the table is:', df[df.duplicated(keep=False)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f316bc",
   "metadata": {},
   "source": [
    "- Check if there is a constant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de6f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature                              Unique Values\n",
      "-------                              --------------- \n",
      "\n",
      "BBLE                                 1128885\n",
      "BORO                                 5\n",
      "BLOCK                                13985\n",
      "LOT                                  6548\n",
      "EASEMENT                             15\n",
      "OWNER                                1470317\n",
      "BLDGCL                               218\n",
      "TAXCLASS                             11\n",
      "LTFRONT                              1328\n",
      "LTDEPTH                              1391\n",
      "EXT                                  4\n",
      "STORIES                              129\n",
      "FULLVAL                              579432\n",
      "AVLAND                               171876\n",
      "AVTOT                                395031\n",
      "EXLAND                               83255\n",
      "EXTOT                                243174\n",
      "EXCD1                                146\n",
      "STADDR                               861582\n",
      "POSTCODE                             239\n",
      "EXMPTCL                              15\n",
      "BLDFRONT                             642\n",
      "BLDDEPTH                             636\n",
      "AVLAND2                              166119\n",
      "AVTOT2                               540297\n",
      "EXLAND2                              101774\n",
      "EXTOT2                               265188\n",
      "EXCD2                                70\n",
      "PERIOD                               1\n",
      "YEAR                                 9\n",
      "VALTYPE                              1\n",
      "Borough                              6\n",
      "Latitude                             296934\n",
      "Longitude                            345998\n",
      "CommunityBoard                       72\n",
      "CouncilDistrict                      52\n",
      "CensusTract                          1328\n",
      "BIN                                  821257\n",
      "NTA                                  196\n",
      "NewGeoreferencedColumn               825755\n"
     ]
    }
   ],
   "source": [
    "#Check the data of category type to see if there is a constant column\n",
    "df_columns = df.columns\n",
    "features_card = list(df[df_columns].columns.values)\n",
    "\n",
    "print('{0:35}  {1}'.format(\"Feature\", \"Unique Values\"))\n",
    "print('{0:35}  {1}'.format(\"-------\", \"--------------- \\n\"))\n",
    "\n",
    "for c in df_columns:\n",
    "    print('{0:35}  {1}'.format(c, str(len(df[c].unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ef1c9",
   "metadata": {},
   "source": [
    "The above result shows that PERIOD, VALTYPE are constant columns, so delete these two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e0e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"PERIOD\", \"VALTYPE\"]\n",
    "df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9699bc",
   "metadata": {},
   "source": [
    "- Check %Missing column and %null column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198a300e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Missing%</th>\n",
       "      <th>Null%</th>\n",
       "      <th>Total%</th>\n",
       "      <th>0%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BORO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EASEMENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.580453</td>\n",
       "      <td>99.580453</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OWNER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.190576</td>\n",
       "      <td>2.190576</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BLDGCL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TAXCLASS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LTFRONT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.022221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LTDEPTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.844120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EXT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.686734</td>\n",
       "      <td>67.686734</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>STORIES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.165401</td>\n",
       "      <td>5.165401</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FULLVAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.298942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AVLAND</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.299176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AVTOT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.298993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EXLAND</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.801498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EXTOT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.930785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EXCD1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.928754</td>\n",
       "      <td>46.928754</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>STADDR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061264</td>\n",
       "      <td>0.061264</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>POSTCODE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.536803</td>\n",
       "      <td>2.536803</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EXMPTCL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.592220</td>\n",
       "      <td>98.592220</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BLDFRONT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.469725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BLDDEPTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.277736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AVLAND2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.503237</td>\n",
       "      <td>72.503237</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AVTOT2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.503034</td>\n",
       "      <td>72.503034</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EXLAND2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.952168</td>\n",
       "      <td>91.952168</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EXTOT2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.509091</td>\n",
       "      <td>87.509091</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EXCD2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.236928</td>\n",
       "      <td>92.236928</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>YEAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Borough</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.474101</td>\n",
       "      <td>3.474101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CommunityBoard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CouncilDistrict</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CensusTract</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.078477</td>\n",
       "      <td>4.078477</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NewGeoreferencedColumn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>3.501402</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Missing%      Null%     Total%         0%\n",
       "0                     BBLE       0.0   0.000000   0.000000   0.000000\n",
       "1                     BORO       0.0   0.000000   0.000000   0.000000\n",
       "2                    BLOCK       0.0   0.000000   0.000000   0.000000\n",
       "3                      LOT       0.0   0.000000   0.000000   0.000000\n",
       "4                 EASEMENT       0.0  99.580453  99.580453   0.000000\n",
       "5                    OWNER       0.0   2.190576   2.190576   0.000000\n",
       "6                   BLDGCL       0.0   0.000000   0.000000   0.000000\n",
       "7                 TAXCLASS       0.0   0.000000   0.000000   0.000000\n",
       "8                  LTFRONT       0.0   0.000000   0.000000  16.022221\n",
       "9                  LTDEPTH       0.0   0.000000   0.000000  16.844120\n",
       "10                     EXT       0.0  67.686734  67.686734   0.000000\n",
       "11                 STORIES       0.0   5.165401   5.165401   0.000000\n",
       "12                 FULLVAL       0.0   0.000000   0.000000   1.298942\n",
       "13                  AVLAND       0.0   0.000000   0.000000   1.299176\n",
       "14                   AVTOT       0.0   0.000000   0.000000   1.298993\n",
       "15                  EXLAND       0.0   0.000000   0.000000  52.801498\n",
       "16                   EXTOT       0.0   0.000000   0.000000  46.930785\n",
       "17                   EXCD1       0.0  46.928754  46.928754   0.000000\n",
       "18                  STADDR       0.0   0.061264   0.061264   0.000000\n",
       "19                POSTCODE       0.0   2.536803   2.536803   0.000000\n",
       "20                 EXMPTCL       0.0  98.592220  98.592220   0.000000\n",
       "21                BLDFRONT       0.0   0.000000   0.000000  22.469725\n",
       "22                BLDDEPTH       0.0   0.000000   0.000000  22.277736\n",
       "23                 AVLAND2       0.0  72.503237  72.503237   0.000000\n",
       "24                  AVTOT2       0.0  72.503034  72.503034   0.000000\n",
       "25                 EXLAND2       0.0  91.952168  91.952168   0.000000\n",
       "26                  EXTOT2       0.0  87.509091  87.509091   0.000000\n",
       "27                   EXCD2       0.0  92.236928  92.236928   0.000000\n",
       "28                    YEAR       0.0   0.000000   0.000000   0.000000\n",
       "29                 Borough       0.0   3.474101   3.474101   0.000000\n",
       "30                Latitude       0.0   3.501402   3.501402   0.000000\n",
       "31               Longitude       0.0   3.501402   3.501402   0.000000\n",
       "32          CommunityBoard       0.0   3.501402   3.501402   0.000000\n",
       "33         CouncilDistrict       0.0   3.501402   3.501402   0.000000\n",
       "34             CensusTract       0.0   3.501402   3.501402   0.000000\n",
       "35                     BIN       0.0   4.078477   4.078477   0.000000\n",
       "36                     NTA       0.0   3.501402   3.501402   0.000000\n",
       "37  NewGeoreferencedColumn       0.0   3.501402   3.501402   0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare %Missing column and %null column\n",
    "categorical_missing = {'Feature':[], 'Missing%':[], 'Null%':[], 'Total%':[], '0%':[]}\n",
    "for column in df.columns:\n",
    "    categorical_missing['Feature'].append(column)\n",
    "    categorical_missing['Missing%'].append(100*sum(df[column]=='Missing')/df.shape[0])\n",
    "    categorical_missing['Null%'].append(100*(df[column].isnull().sum())/df.shape[0])\n",
    "    categorical_missing['Total%'].append((100*sum(df[column]=='Missing')/df.shape[0])+(100*(df[column].isnull().sum())/df.shape[0]))\n",
    "    categorical_missing['0%'].append(100 * len(df[df[column] == 0]) / df.shape[0])\n",
    "pd.DataFrame(categorical_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd6d65f",
   "metadata": {},
   "source": [
    "###### BORO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa89e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BORO'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9936b96",
   "metadata": {},
   "source": [
    "- BORO is a field indicating the administrative division of real estate. It is commonly used to identify boroughs in New York City.\n",
    "- 1, Manhattan; 2, Brooklyn; 3, Queens; 4, Bronx; 5, Staten Island.\n",
    "- Since this project focuses on Manhattan, the data with BORO value 1 is filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a2ceefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['BORO'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df4105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['BORO'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd33b87",
   "metadata": {},
   "source": [
    "###### EASEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3797edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'E', 'G', 'F', 'A', 'H', 'I', 'N', 'K'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EASEMENT'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb5ae3",
   "metadata": {},
   "source": [
    "- In the EASEMENT column, these values indicate the easement status of the property. An easement is a specific right or restriction on the use of land without ownership. These values represent the various easement types that may exist in the area where the property is located. NaN indicates missing values, that is, no easement information is available.\n",
    "- Considering that over 99.5 % of buildings have no easement, this attribute has almost zero impact on the analysis, so this should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faf2e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['EASEMENT'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48bef95",
   "metadata": {},
   "source": [
    "###### OWNER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf2d74",
   "metadata": {},
   "source": [
    "- The owner will not affect the value of the building, and in order to ensure personal privacy，this should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f73d4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['OWNER'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0ca49",
   "metadata": {},
   "source": [
    "###### EXMPTCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1a16710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'X1', 'X4', 'X8', 'X6', 'X5', 'X2', 'VI', 'X7', 'X3', 'X9',\n",
       "       'KI'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EXMPTCL'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d7077",
   "metadata": {},
   "source": [
    "- In the EASEMENT column, these values indicate the tax exemption category to which the property belongs. Nan values are guessed as no tax-exempt status.\n",
    "- Since over 98.5% of the values are missing, the impact of this attribute on the analysis is almost zero, so this should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c1bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['EXMPTCL'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8510e7",
   "metadata": {},
   "source": [
    "###### AVLAND, AVLAND2 and AVTOT, AVTOT2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399bd3f6",
   "metadata": {},
   "source": [
    "- Both are the first valuation and the second valuation. It is speculated that the second valuation is vacant because the second valuation is the same as the first valuation. Therefore, fill the vacant values of the second valuation with the first valuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afbb2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['AVLAND2'].isnull(), 'AVLAND2'] = df['AVLAND']\n",
    "df.loc[df['AVTOT2'].isnull(), 'AVTOT2'] = df['AVTOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35476616",
   "metadata": {},
   "source": [
    "- If AVLAND, AVLAND2, AVTOT, AVTOT2 and FULLVAL are all empty, the house value cannot be determined. So  this should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e5b906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FULLVAL', 'AVLAND', 'AVTOT', 'AVLAND2', 'AVTOT2']\n",
    "df = df[~(df[columns] == 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80a7e5",
   "metadata": {},
   "source": [
    "###### EXLAND, EXLAND2 and EXTOT, EXTOT2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7e64d",
   "metadata": {},
   "source": [
    "- Same reason as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68a9e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['EXLAND2'].isnull(), 'EXLAND2'] = df['EXLAND']\n",
    "df.loc[df['EXTOT2'].isnull(), 'EXTOT2'] = df['EXTOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f858cf",
   "metadata": {},
   "source": [
    "###### Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2dd6a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'MANHATTAN'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Borough'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254e0533",
   "metadata": {},
   "source": [
    "- The administrative division in which the immovable property is located, a string indicating the administrative division.\n",
    "- We have filtered out the real estate belonging to Manhattan by BORO, and the real estate data we know to be retained belongs to Manhattan. At the same time, we know that Borough has only two values: MANHATTAN and nan, so that column is useless for us. This should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1456ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['Borough'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ada385",
   "metadata": {},
   "source": [
    "###### NTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d862e",
   "metadata": {},
   "source": [
    "- Since the addresses are associated, the \"BLOCK\" and \"NTA\" columns of all data are taken out to remove duplicate values and observe whether there is a corresponding relationship between the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a95e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_combinations = df[['BLOCK', 'NTA']].drop_duplicates()\n",
    "unique_combinations.to_csv('programing data/unique_combinations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "430f47ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>NTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>274</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911181</th>\n",
       "      <td>2038</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912822</th>\n",
       "      <td>2031</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916755</th>\n",
       "      <td>2028</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8918224</th>\n",
       "      <td>2025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8922131</th>\n",
       "      <td>2027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BLOCK  NTA\n",
       "0           16  NaN\n",
       "1           73  NaN\n",
       "4           36  NaN\n",
       "11         209  NaN\n",
       "18         274  NaN\n",
       "...        ...  ...\n",
       "8911181   2038  NaN\n",
       "8912822   2031  NaN\n",
       "8916755   2028  NaN\n",
       "8918224   2025  NaN\n",
       "8922131   2027  NaN\n",
       "\n",
       "[2575 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(unique_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967ee1a",
   "metadata": {},
   "source": [
    "-  It is found that there are three cases, the BLOCK number corresponds to one NTA value, the BLOCK number corresponds to two values: null value and NTA name, and the BLOCK corresponds to three values: null value, NTA name 1 and NTA name 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33bd923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_counts = unique_combinations['BLOCK'].value_counts()\n",
    "block_once = block_counts[block_counts == 1].index\n",
    "block_twice = block_counts[block_counts == 2].index\n",
    "block_thrice = block_counts[block_counts == 3].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a61f3a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of BLOCK values that appear once： 1367\n",
      "The total number of BLOCK values that appear twice： 553\n",
      "The total number of BLOCK values that appear Three： 34\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of BLOCK values that appear once：\", len(block_once))\n",
    "print(\"The total number of BLOCK values that appear twice：\", len(block_twice))\n",
    "print(\"The total number of BLOCK values that appear Three：\", len(block_thrice))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf87d99",
   "metadata": {},
   "source": [
    "- To fill the missing NTA values with another NTA value corresponding to the same BLOCK value when NTA is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c20de9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_nta_mapping = df.groupby('BLOCK')['NTA'].first().to_dict()\n",
    "df['NTA'] = df['NTA'].fillna(df['BLOCK'].map(block_nta_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a30a55",
   "metadata": {},
   "source": [
    "- Re-save and observe the data group of [BLOCK-NTA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fece886",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_combinations = df[['BLOCK', 'NTA']].drop_duplicates()\n",
    "unique_combinations.to_csv('programing data/unique_combinations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b2738",
   "metadata": {},
   "source": [
    "- The remaining vacancy values are filled by the NTA corresponding to the BLOCK with the closest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7bd5ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('BLOCK', ascending=False)\n",
    "df['NTA'] = df['NTA'].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756bb94b",
   "metadata": {},
   "source": [
    "- The LocationID is obtained according to the NTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "497cdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zone = pd.read_csv('programing data/taxi_zones.csv', usecols=['zone','LocationID'])\n",
    "merged_df = pd.merge(df, taxi_zone, left_on='NTA', right_on = 'zone', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5258516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([243, 244, 116, 152, 166,  74,  75, 148, 107, 249,  79,  45])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['LocationID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e05c70",
   "metadata": {},
   "source": [
    "- There are 69 neighborhoods in Manhattan, and the data has been processed to show only 12 of them. The data cannot be used,  so this should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e87b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=['NTA'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19d987",
   "metadata": {},
   "source": [
    "###### Latitude and Longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a57e078",
   "metadata": {},
   "source": [
    "- The latitude and longitude cannot be filled with other data.\n",
    "- Query for data where the latitude and longitude and New Georeferenced Column are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06f4dfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1352026, 32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ddbc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = df[df['Longitude'].isnull() & df['Latitude'].isnull()& df['NewGeoreferencedColumn'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33e472c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10967, 32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47a7f772",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBLE</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>BLDGCL</th>\n",
       "      <th>TAXCLASS</th>\n",
       "      <th>LTFRONT</th>\n",
       "      <th>LTDEPTH</th>\n",
       "      <th>EXT</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>FULLVAL</th>\n",
       "      <th>...</th>\n",
       "      <th>EXTOT2</th>\n",
       "      <th>EXCD2</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CommunityBoard</th>\n",
       "      <th>CouncilDistrict</th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>BIN</th>\n",
       "      <th>NewGeoreferencedColumn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4572147</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014/15</td>\n",
       "      <td>40.798896</td>\n",
       "      <td>-73.940188</td>\n",
       "      <td>111.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>POINT (-73.940188 40.798896)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736323</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012/13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473558</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>369000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015/16</td>\n",
       "      <td>40.798896</td>\n",
       "      <td>-73.940188</td>\n",
       "      <td>111.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>POINT (-73.940188 40.798896)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835294</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010/11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647665</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013/14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394511</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016/17</td>\n",
       "      <td>40.798896</td>\n",
       "      <td>-73.940188</td>\n",
       "      <td>111.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>POINT (-73.940188 40.798896)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171194</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>452000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018/19</td>\n",
       "      <td>40.798896</td>\n",
       "      <td>-73.940188</td>\n",
       "      <td>111.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>POINT (-73.940188 40.798896)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284215</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>416000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017/18</td>\n",
       "      <td>40.798896</td>\n",
       "      <td>-73.940188</td>\n",
       "      <td>111.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>POINT (-73.940188 40.798896)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8896625</th>\n",
       "      <td>1016440042</td>\n",
       "      <td>1644</td>\n",
       "      <td>42</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>296000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011/12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               BBLE  BLOCK  LOT BLDGCL TAXCLASS  LTFRONT  LTDEPTH  EXT  \\\n",
       "4572147  1016440042   1644   42     V1        4       25       72  NaN   \n",
       "6736323  1016440042   1644   42     V1        4       25       72  NaN   \n",
       "3473558  1016440042   1644   42     V1        4       25       72  NaN   \n",
       "7835294  1016440042   1644   42     V1        4       25       72  NaN   \n",
       "5647665  1016440042   1644   42     V1        4       25       72  NaN   \n",
       "2394511  1016440042   1644   42     V1        4       25       72  NaN   \n",
       "171194   1016440042   1644   42     V1        4       25       72  NaN   \n",
       "1284215  1016440042   1644   42     V1        4       25       72  NaN   \n",
       "8896625  1016440042   1644   42     V1        4       25       72  NaN   \n",
       "\n",
       "         STORIES  FULLVAL  ...  EXTOT2  EXCD2     YEAR   Latitude  Longitude  \\\n",
       "4572147      NaN   323000  ...     0.0    NaN  2014/15  40.798896 -73.940188   \n",
       "6736323      NaN   301000  ...     0.0    NaN  2012/13        NaN        NaN   \n",
       "3473558      NaN   369000  ...     0.0    NaN  2015/16  40.798896 -73.940188   \n",
       "7835294      NaN   296200  ...     0.0    NaN  2010/11        NaN        NaN   \n",
       "5647665      NaN   311217  ...     0.0    NaN  2013/14        NaN        NaN   \n",
       "2394511      NaN   389000  ...     0.0    NaN  2016/17  40.798896 -73.940188   \n",
       "171194       NaN   452000  ...     0.0    NaN  2018/19  40.798896 -73.940188   \n",
       "1284215      NaN   416000  ...     0.0    NaN  2017/18  40.798896 -73.940188   \n",
       "8896625      NaN   296000  ...     0.0    NaN  2011/12        NaN        NaN   \n",
       "\n",
       "        CommunityBoard  CouncilDistrict  CensusTract        BIN  \\\n",
       "4572147          111.0              8.0        182.0  1000000.0   \n",
       "6736323            NaN              NaN          NaN        NaN   \n",
       "3473558          111.0              8.0        182.0  1000000.0   \n",
       "7835294            NaN              NaN          NaN        NaN   \n",
       "5647665            NaN              NaN          NaN        NaN   \n",
       "2394511          111.0              8.0        182.0  1000000.0   \n",
       "171194           111.0              8.0        182.0  1000000.0   \n",
       "1284215          111.0              8.0        182.0  1000000.0   \n",
       "8896625            NaN              NaN          NaN        NaN   \n",
       "\n",
       "               NewGeoreferencedColumn  \n",
       "4572147  POINT (-73.940188 40.798896)  \n",
       "6736323                           NaN  \n",
       "3473558  POINT (-73.940188 40.798896)  \n",
       "7835294                           NaN  \n",
       "5647665                           NaN  \n",
       "2394511  POINT (-73.940188 40.798896)  \n",
       "171194   POINT (-73.940188 40.798896)  \n",
       "1284215  POINT (-73.940188 40.798896)  \n",
       "8896625                           NaN  \n",
       "\n",
       "[9 rows x 32 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['BBLE']=='1016440042']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992aa49f",
   "metadata": {},
   "source": [
    "- The data lacks latitude and longitude data. However, some data of the same building have latitude and longitude data and some do not. The same BBLE is used to group data and fill the missing latitude and longitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cd679ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('BBLE')\n",
    "for name, group in grouped:\n",
    "    if group['Latitude'].nunique(dropna = False) != 1:\n",
    "        valid_lat = group['Latitude'].dropna().drop_duplicates()\n",
    "        valid_lon = group['Longitude'].dropna().drop_duplicates()\n",
    "        df.loc[group.index, 'Latitude'] = group['Latitude'].fillna(valid_lat.values[0])\n",
    "        df.loc[group.index, 'Longitude'] = group['Longitude'].fillna(valid_lon.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b1993",
   "metadata": {},
   "source": [
    "- Using latitude and longitude to determine what zone the real estate belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab0ed8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the csv file of the zone data\n",
    "region_data = pd.read_csv('programing data/taxi_zones.csv')\n",
    "# creating a list of polygon objects for the area\n",
    "region_polygons = []\n",
    "region_ids = []  # area id list\n",
    "\n",
    "for index, row in region_data.iloc[:].iterrows():\n",
    "    geom_value = row['the_geom']\n",
    "    cleaned_value = geom_value.lstrip('MULTIPOLYGON ')\n",
    "    coordinates = cleaned_value.replace('(', '').replace(')', '').split(',')\n",
    "    coordinates = [tuple(map(float, coord.strip().split())) for coord in coordinates]\n",
    "    polygon = Polygon(coordinates)\n",
    "    region_polygons.append(polygon)\n",
    "    region_ids.append(row['LocationID'])\n",
    "\n",
    "df['LocationID'] = None  # Creatinga new column and initialize it to None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Latitude'] != \"\" and row['Longitude'] != \"\":\n",
    "        house_latitude = row['Latitude']\n",
    "        house_longitude = row['Longitude']\n",
    "        house_point = Point(house_longitude, house_latitude)\n",
    "    \n",
    "    \n",
    "        # Checking if the property is in either zone\n",
    "        for i, polygon in enumerate(region_polygons):\n",
    "            if house_point.within(polygon):\n",
    "                df.at[index, 'LocationID'] = region_ids[i]\n",
    "                break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5d0fc",
   "metadata": {},
   "source": [
    "- See if the building LocationID can be inferred from the same address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83897abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 75, 233, 224], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['STADDR'] == '1 AVENUE', \"LocationID\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feefa619",
   "metadata": {},
   "source": [
    "- It is observed that the same address may belong to 2-3 different neighborhoods, and it is impossible to predicted the neighborhood by the address.\n",
    "- Remove data without latitude and longitude values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35fd568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df[\"Latitude\"].isna() & df[\"Longitude\"].isna() ))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd77098",
   "metadata": {},
   "source": [
    "###### YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9565fe",
   "metadata": {},
   "source": [
    "- Data from 2015 and beyond will be kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39e094db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2010/11', '2011/12', '2017/18', '2016/17', '2018/19', '2013/14',\n",
       "       '2014/15', '2015/16', '2012/13'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['YEAR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d563d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_to_delete = ['2013/14', '2012/13', '2010/11', '2011/12']\n",
    "df = df[~df['YEAR'].isin(years_to_delete)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29619ce",
   "metadata": {},
   "source": [
    "- Check %Missing column and %null column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b92373be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Missing%</th>\n",
       "      <th>Null%</th>\n",
       "      <th>Total%</th>\n",
       "      <th>0%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLOCK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLDGCL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAXCLASS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LTFRONT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.678799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LTDEPTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.061184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.430590</td>\n",
       "      <td>93.430590</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STORIES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.068378</td>\n",
       "      <td>3.068378</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FULLVAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AVLAND</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AVTOT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EXLAND</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.043552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EXTOT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.855641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EXCD1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.854332</td>\n",
       "      <td>65.854332</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>STADDR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>POSTCODE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BLDFRONT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.636689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BLDDEPTH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.623468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AVLAND2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AVTOT2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EXLAND2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.007290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EXTOT2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.854332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EXCD2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.787113</td>\n",
       "      <td>97.787113</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>YEAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CommunityBoard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CouncilDistrict</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CensusTract</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478865</td>\n",
       "      <td>0.478865</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NewGeoreferencedColumn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LocationID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Missing%      Null%     Total%         0%\n",
       "0                     BBLE       0.0   0.000000   0.000000   0.000000\n",
       "1                    BLOCK       0.0   0.000000   0.000000   0.000000\n",
       "2                      LOT       0.0   0.000000   0.000000   0.000000\n",
       "3                   BLDGCL       0.0   0.000000   0.000000   0.000000\n",
       "4                 TAXCLASS       0.0   0.000000   0.000000   0.000000\n",
       "5                  LTFRONT       0.0   0.000000   0.000000  57.678799\n",
       "6                  LTDEPTH       0.0   0.000000   0.000000  58.061184\n",
       "7                      EXT       0.0  93.430590  93.430590   0.000000\n",
       "8                  STORIES       0.0   3.068378   3.068378   0.000000\n",
       "9                  FULLVAL       0.0   0.000000   0.000000   0.000000\n",
       "10                  AVLAND       0.0   0.000000   0.000000   0.000655\n",
       "11                   AVTOT       0.0   0.000000   0.000000   0.000000\n",
       "12                  EXLAND       0.0   0.000000   0.000000  79.043552\n",
       "13                   EXTOT       0.0   0.000000   0.000000  65.855641\n",
       "14                   EXCD1       0.0  65.854332  65.854332   0.000000\n",
       "15                  STADDR       0.0   0.003142   0.003142   0.000000\n",
       "16                POSTCODE       0.0   0.018065   0.018065   0.000000\n",
       "17                BLDFRONT       0.0   0.000000   0.000000  60.636689\n",
       "18                BLDDEPTH       0.0   0.000000   0.000000  60.623468\n",
       "19                 AVLAND2       0.0   0.000000   0.000000   0.000655\n",
       "20                  AVTOT2       0.0   0.000000   0.000000   0.000000\n",
       "21                 EXLAND2       0.0   0.000000   0.000000  79.007290\n",
       "22                  EXTOT2       0.0   0.000000   0.000000  65.854332\n",
       "23                   EXCD2       0.0  97.787113  97.787113   0.000000\n",
       "24                    YEAR       0.0   0.000000   0.000000   0.000000\n",
       "25                Latitude       0.0   0.000000   0.000000   0.000000\n",
       "26               Longitude       0.0   0.000000   0.000000   0.000000\n",
       "27          CommunityBoard       0.0   0.091505   0.091505   0.000000\n",
       "28         CouncilDistrict       0.0   0.091505   0.091505   0.000000\n",
       "29             CensusTract       0.0   0.091505   0.091505   0.000000\n",
       "30                     BIN       0.0   0.478865   0.478865   0.000000\n",
       "31  NewGeoreferencedColumn       0.0   0.091505   0.091505   0.000000\n",
       "32              LocationID       0.0   0.001309   0.001309   0.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare %Missing column and %null column\n",
    "categorical_missing = {'Feature':[], 'Missing%':[], 'Null%':[], 'Total%':[], '0%':[]}\n",
    "for column in df.columns:\n",
    "    categorical_missing['Feature'].append(column)\n",
    "    categorical_missing['Missing%'].append(100*sum(df[column]=='Missing')/df.shape[0])\n",
    "    categorical_missing['Null%'].append(100*(df[column].isnull().sum())/df.shape[0])\n",
    "    categorical_missing['Total%'].append((100*sum(df[column]=='Missing')/df.shape[0])+(100*(df[column].isnull().sum())/df.shape[0]))\n",
    "    categorical_missing['0%'].append(100 * len(df[df[column] == 0]) /df.shape[0])\n",
    "pd.DataFrame(categorical_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6efbaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('programing data/Property_Valuation_and_Assessment_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7c8f1",
   "metadata": {},
   "source": [
    "### Selecting features："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b4863e",
   "metadata": {},
   "source": [
    "- Look for rows and columns. Consider whether it makes sense to keep them or drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b3ad0",
   "metadata": {},
   "source": [
    "Feature Selection Summary:\n",
    "\n",
    "- Real Estate:\n",
    "| Feature                                |    Data Plan                                         |\n",
    "|----------------------------------------|--------------------------------------|\n",
    "|     BBLE               |   Inherit BBLE from the original dataset                                          |     \n",
    "|     BLDGCL             |   Inherit BLDGCL from the original dataset                                  |    \n",
    "|     TAXCLASS           |   Inherit TAXCLASS from the original dataset                                  |    \n",
    "|     EXT                |   Inherit EXT from the original dataset                                          |    \n",
    "|     STORIES            |   Inherit STORIES from the original dataset                                  |    \n",
    "|     FULLVAL            |   Inherit FULLVAL from the original dataset                                  |     \n",
    "|     AVLAND             |   Average of AVLAND and AVLAND2 from the original dataset                         |    \n",
    "|     AVTOT\t             |   Average of AVTOT and AVTOT2 from the original dataset                         |    \n",
    "|     EXLAND             |   Average of EXLAND and EXLAND2 from the original dataset                         |    \n",
    "|     EXTOT              |   Average of EXTOT and EXTOT2 from the original dataset                         |        \n",
    "|     YEAR               |   Inherit YEAR from the original dataset, slice the first 4 characters    |     \n",
    "|     LocationID         |   Inherit LocationID from the original dataset                                  |     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "38beb514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/ybj4cz9s1wd3hg435tvgpfb00000gn/T/ipykernel_17313/906282737.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['AVLAND'] = (df['AVLAND'] + df['AVLAND2']) / 2\n",
      "/var/folders/6g/ybj4cz9s1wd3hg435tvgpfb00000gn/T/ipykernel_17313/906282737.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['AVTOT'] = (df['AVTOT'] + df['AVTOT2']) / 2\n",
      "/var/folders/6g/ybj4cz9s1wd3hg435tvgpfb00000gn/T/ipykernel_17313/906282737.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['EXLAND'] = (df['EXLAND'] + df['EXLAND2']) / 2\n",
      "/var/folders/6g/ybj4cz9s1wd3hg435tvgpfb00000gn/T/ipykernel_17313/906282737.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['EXTOT'] = (df['EXTOT'] + df['EXTOT2']) / 2\n",
      "/var/folders/6g/ybj4cz9s1wd3hg435tvgpfb00000gn/T/ipykernel_17313/906282737.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['YEAR'] = df['YEAR'].str[:4]\n"
     ]
    }
   ],
   "source": [
    "new_df = df[['BBLE', 'BLDGCL', 'TAXCLASS', 'EXT', 'STORIES', 'FULLVAL', 'LocationID']]\n",
    "new_df['AVLAND'] = (df['AVLAND'] + df['AVLAND2']) / 2\n",
    "new_df['AVTOT'] = (df['AVTOT'] + df['AVTOT2']) / 2\n",
    "new_df['EXLAND'] = (df['EXLAND'] + df['EXLAND2']) / 2\n",
    "new_df['EXTOT'] = (df['EXTOT'] + df['EXTOT2']) / 2\n",
    "new_df['YEAR'] = df['YEAR'].str[:4]\n",
    "new_df.to_csv('programing data/Real_Estate.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c900ee",
   "metadata": {},
   "source": [
    "- NTA real estate\n",
    "| Feature                                |    Data Plan                                         |\n",
    "|----------------------------------------|--------------------------------------| \n",
    "|     BLDGCL             |   Class of building                                                              |          \n",
    "|     AMOUNT             |   The total number of buildings                                                  |    \n",
    "|     FULLVAL            |   The sum of the 'FULLVAL' of all the buildings in the area                    |     \n",
    "|     AVLAND             |   The sum of the 'AVLAND' of all the buildings in the area                    |    \n",
    "|     AVTOT\t             |   The sum of the 'AVTOT' of all the buildings in the area                    |    \n",
    "|     EXLAND             |   The sum of the 'EXLAND' of all the buildings in the area                    |    \n",
    "|     EXTOT              |   The sum of the 'EXTOT' of all the buildings in the area                    |        \n",
    "|     YEAR               |   Inherit YEAR from the original dataset                                          |     \n",
    "|     LocationID         |   The NTA where the property is located    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd3f9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df\n",
    "new_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d57e1d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.groupby(['YEAR', 'BLDGCL', 'LocationID']).agg({\n",
    "    'BBLE': 'count',  # Total number of statistics\n",
    "    'AVLAND': 'sum',  \n",
    "    'FULLVAL': 'sum',  \n",
    "    'AVTOT': 'sum',\n",
    "    'EXLAND':'sum',\n",
    "    'EXTOT':'sum'  \n",
    "}).reset_index()\n",
    "new_df.columns = ['YEAR', 'BLDGCL', 'LocationID', 'AMOUNT', 'AVLAND', 'FULLVAL', 'AVTOT','EXLAND','EXTOT']\n",
    "new_df.to_csv('programing data/NTA_Real_Estate.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2071a",
   "metadata": {},
   "source": [
    "### 2.3 Taxi Trip Deta:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35aeb2",
   "metadata": {},
   "source": [
    "#### Explain the meaning of each feature\n",
    "- VendorID: The identifier of the taxi provider or operator.\n",
    "- tpep_pickup_datetime: The date and time of the pick-up.\n",
    "- tpep_dropoff_datetime: The date and time of the drop-off.\n",
    "- passenger_count: Number of passengers.\n",
    "- trip_distance: Travel distance\n",
    "- pickup_longitude: The longitude coordinate of the pick-up.\n",
    "- pickup_latitude: The latitudinal coordinates of the pick-up.\n",
    "- RatecodeID: A code that identifies the taxi rate.\n",
    "- store_and_fwd_flag: Is a field in New York City taxi data that records a Boolean value indicating whether the trip was stored locally by the vehicle and subsequently forwarded to the dispatch center.\n",
    "- dropoff_longitude: The longitude coordinate of the drop-off.\n",
    "- dropoff_latitude: The latitudinal coordinates of the drop-off.\n",
    "- payment_type: Payment method for passengers.\n",
    "- fare_amount: The amount of the trip cost, excluding surcharges, tips, tolls, etc.\n",
    "- extra: Additional charges, which may include parking fees, baggage fees, etc.\n",
    "- mta_tax: Nyc Transit Authority (MTA) additional taxes and fees.\n",
    "- tip_amount: The amount of a tip given by a passenger.\n",
    "- tolls_amount: The amount of the toll.\n",
    "- improvement_surcharge: An improvement surcharge, usually a fee charged under certain conditions.\n",
    "- total_amount: The total cost, including the sum of the trip cost, additional fees, tips, tolls and other surcharges.\n",
    "- PULocationID: The location ID of the pick-up.\n",
    "- DOLocationID: The location ID of the drop-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27bbce",
   "metadata": {},
   "source": [
    "#### New feature\n",
    "- Year: Year of data generation.\n",
    "- LocationID: The location ID.\n",
    "- Pick_up: The count of the pick-up.\n",
    "- Drop_off: The count of the drop-off.\n",
    "- Pick_up_passenger: The number of passengers of pick_up.\n",
    "- Drop_off_passenger: The number of passengers of drop_off.\n",
    "- Pick_up_fare: The total cost of the number of passengers of pick_up.\n",
    "- Drop_off_fare: The total cost of the number of passengers of drop_off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f741d",
   "metadata": {},
   "source": [
    "### Cleaning data\n",
    "Take 2016 for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf35a665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/ybj4cz9s1wd3hg435tvgpfb00000gn/T/ipykernel_17313/3409598886.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"dataSource/2016_Yellow_Taxi_Trip_Data.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataSource/2016_Yellow_Taxi_Trip_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d6f10be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>08/12/2016 11:55:28 AM</td>\n",
       "      <td>08/12/2016 12:07:57 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>230.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>07/20/2016 02:36:59 PM</td>\n",
       "      <td>07/20/2016 03:26:37 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>63.35</td>\n",
       "      <td>162.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>07/05/2016 09:21:27 PM</td>\n",
       "      <td>07/05/2016 09:39:07 PM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.75</td>\n",
       "      <td>231.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>07/09/2016 11:39:16 PM</td>\n",
       "      <td>07/09/2016 11:44:16 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.30</td>\n",
       "      <td>186.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>07/11/2016 10:42:40 PM</td>\n",
       "      <td>07/11/2016 10:52:42 PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>161.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  \\\n",
       "0        1  08/12/2016 11:55:28 AM  08/12/2016 12:07:57 PM              1.0   \n",
       "1        1  07/20/2016 02:36:59 PM  07/20/2016 03:26:37 PM              1.0   \n",
       "2        2  07/05/2016 09:21:27 PM  07/05/2016 09:39:07 PM              2.0   \n",
       "3        1  07/09/2016 11:39:16 PM  07/09/2016 11:44:16 PM              1.0   \n",
       "4        2  07/11/2016 10:42:40 PM  07/11/2016 10:52:42 PM              5.0   \n",
       "\n",
       "   trip_distance  pickup_longitude  pickup_latitude  RatecodeID  \\\n",
       "0           0.80               NaN              NaN         1.0   \n",
       "1          15.30               NaN              NaN         2.0   \n",
       "2           3.56               NaN              NaN         1.0   \n",
       "3           0.70               NaN              NaN         1.0   \n",
       "4           1.27               NaN              NaN         1.0   \n",
       "\n",
       "  store_and_fwd_flag  dropoff_longitude  ...  payment_type  fare_amount  \\\n",
       "0                  N                NaN  ...           2.0          8.5   \n",
       "1                  N                NaN  ...           1.0         52.0   \n",
       "2                  N                NaN  ...           1.0         14.5   \n",
       "3                  N                NaN  ...           2.0          5.0   \n",
       "4                  N                NaN  ...           2.0          8.0   \n",
       "\n",
       "   extra  mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "0    0.0      0.5        0.00           0.0                    0.3   \n",
       "1    0.0      0.5       10.55           0.0                    0.3   \n",
       "2    0.5      0.5        3.95           0.0                    0.3   \n",
       "3    0.5      0.5        0.00           0.0                    0.3   \n",
       "4    0.5      0.5        0.00           0.0                    0.3   \n",
       "\n",
       "   total_amount  PULocationID  DOLocationID  \n",
       "0          9.30         230.0         229.0  \n",
       "1         63.35         162.0         132.0  \n",
       "2         19.75         231.0         181.0  \n",
       "3          6.30         186.0         234.0  \n",
       "4          9.30         161.0         100.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f95c2",
   "metadata": {},
   "source": [
    "- Check how many rows and columns dataset has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fedad123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12867402, 21)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f2bdc",
   "metadata": {},
   "source": [
    "- Check database data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe51f46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                  object\n",
       "tpep_pickup_datetime      object\n",
       "tpep_dropoff_datetime     object\n",
       "passenger_count          float64\n",
       "trip_distance            float64\n",
       "pickup_longitude         float64\n",
       "pickup_latitude          float64\n",
       "RatecodeID               float64\n",
       "store_and_fwd_flag        object\n",
       "dropoff_longitude        float64\n",
       "dropoff_latitude         float64\n",
       "payment_type             float64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "PULocationID             float64\n",
       "DOLocationID             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662200c1",
   "metadata": {},
   "source": [
    "- Check if there are duplicate rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e53358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'pickup_longitude',\n",
       "       'pickup_latitude', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'payment_type', 'fare_amount',\n",
       "       'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
       "       'improvement_surcharge', 'total_amount', 'PULocationID',\n",
       "       'DOLocationID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove whitespace in or around feature names\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "#check to ensure whitespaces have been removed\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3093f7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate (excluding first) rows in the table is:  1\n",
      "Number of duplicate rows (including first) in the table is: 2\n"
     ]
    }
   ],
   "source": [
    "#check for duplicate rows\n",
    "\n",
    "#Print the number of duplicates, without the original rows that were duplicated\n",
    "print('Number of duplicate (excluding first) rows in the table is: ', df.duplicated().sum())\n",
    "\n",
    "# Use \"keep=False\" to mark all duplicates as true, including the original rows that were duplicated.\n",
    "print('Number of duplicate rows (including first) in the table is:', df[df.duplicated(keep=False)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a8626",
   "metadata": {},
   "source": [
    "There is only one duplicate data, remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c661cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f9113",
   "metadata": {},
   "source": [
    "- Check if there is a constant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a61ed231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature                              Unique Values\n",
      "-------                              --------------- \n",
      "\n",
      "VendorID                             10\n",
      "tpep_pickup_datetime                 8323781\n",
      "tpep_dropoff_datetime                8325244\n",
      "passenger_count                      11\n",
      "trip_distance                        4758\n",
      "pickup_longitude                     1\n",
      "pickup_latitude                      1\n",
      "RatecodeID                           8\n",
      "store_and_fwd_flag                   3\n",
      "dropoff_longitude                    1\n",
      "dropoff_latitude                     1\n",
      "payment_type                         6\n",
      "fare_amount                          2102\n",
      "extra                                45\n",
      "mta_tax                              12\n",
      "tip_amount                           3930\n",
      "tolls_amount                         1090\n",
      "improvement_surcharge                5\n",
      "total_amount                         12598\n",
      "PULocationID                         262\n",
      "DOLocationID                         263\n"
     ]
    }
   ],
   "source": [
    "#Check the data of category type to see if there is a constant column\n",
    "df_columns = df.columns\n",
    "features_card = list(df[df_columns].columns.values)\n",
    "\n",
    "print('{0:35}  {1}'.format(\"Feature\", \"Unique Values\"))\n",
    "print('{0:35}  {1}'.format(\"-------\", \"--------------- \\n\"))\n",
    "\n",
    "for c in df_columns:\n",
    "    print('{0:35}  {1}'.format(c, str(len(df[c].unique()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748963e",
   "metadata": {},
   "source": [
    "The above result shows that pickup_longitude , pickup_latitude, dropoff_longitude, dropoff_latitude are constant columns, so delete these four columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9fcb5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]\n",
    "df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e69d8a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>08/12/2016 11:55:28 AM</td>\n",
       "      <td>08/12/2016 12:07:57 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>230.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>07/20/2016 02:36:59 PM</td>\n",
       "      <td>07/20/2016 03:26:37 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>63.35</td>\n",
       "      <td>162.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>07/05/2016 09:21:27 PM</td>\n",
       "      <td>07/05/2016 09:39:07 PM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.75</td>\n",
       "      <td>231.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>07/09/2016 11:39:16 PM</td>\n",
       "      <td>07/09/2016 11:44:16 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.30</td>\n",
       "      <td>186.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>07/11/2016 10:42:40 PM</td>\n",
       "      <td>07/11/2016 10:52:42 PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>161.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  \\\n",
       "0        1  08/12/2016 11:55:28 AM  08/12/2016 12:07:57 PM              1.0   \n",
       "1        1  07/20/2016 02:36:59 PM  07/20/2016 03:26:37 PM              1.0   \n",
       "2        2  07/05/2016 09:21:27 PM  07/05/2016 09:39:07 PM              2.0   \n",
       "3        1  07/09/2016 11:39:16 PM  07/09/2016 11:44:16 PM              1.0   \n",
       "4        2  07/11/2016 10:42:40 PM  07/11/2016 10:52:42 PM              5.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  payment_type  fare_amount  \\\n",
       "0           0.80         1.0                  N           2.0          8.5   \n",
       "1          15.30         2.0                  N           1.0         52.0   \n",
       "2           3.56         1.0                  N           1.0         14.5   \n",
       "3           0.70         1.0                  N           2.0          5.0   \n",
       "4           1.27         1.0                  N           2.0          8.0   \n",
       "\n",
       "   extra  mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "0    0.0      0.5        0.00           0.0                    0.3   \n",
       "1    0.0      0.5       10.55           0.0                    0.3   \n",
       "2    0.5      0.5        3.95           0.0                    0.3   \n",
       "3    0.5      0.5        0.00           0.0                    0.3   \n",
       "4    0.5      0.5        0.00           0.0                    0.3   \n",
       "\n",
       "   total_amount  PULocationID  DOLocationID  \n",
       "0          9.30         230.0         229.0  \n",
       "1         63.35         162.0         132.0  \n",
       "2         19.75         231.0         181.0  \n",
       "3          6.30         186.0         234.0  \n",
       "4          9.30         161.0         100.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869407ab",
   "metadata": {},
   "source": [
    "- Check %Missing column and %null column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c657ae10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Missing%</th>\n",
       "      <th>Null%</th>\n",
       "      <th>Total%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VendorID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tpep_pickup_datetime</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpep_dropoff_datetime</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RatecodeID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>store_and_fwd_flag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>payment_type</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fare_amount</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>extra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mta_tax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tip_amount</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>improvement_surcharge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>total_amount</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature  Missing%     Null%    Total%\n",
       "0                VendorID       0.0  0.000000  0.000000\n",
       "1    tpep_pickup_datetime       0.0  0.000031  0.000031\n",
       "2   tpep_dropoff_datetime       0.0  0.000039  0.000039\n",
       "3         passenger_count       0.0  0.000039  0.000039\n",
       "4           trip_distance       0.0  0.000039  0.000039\n",
       "5              RatecodeID       0.0  0.000039  0.000039\n",
       "6      store_and_fwd_flag       0.0  0.000039  0.000039\n",
       "7            payment_type       0.0  0.000039  0.000039\n",
       "8             fare_amount       0.0  0.000039  0.000039\n",
       "9                   extra       0.0  0.000039  0.000039\n",
       "10                mta_tax       0.0  0.000039  0.000039\n",
       "11             tip_amount       0.0  0.000039  0.000039\n",
       "12           tolls_amount       0.0  0.000039  0.000039\n",
       "13  improvement_surcharge       0.0  0.000039  0.000039\n",
       "14           total_amount       0.0  0.000039  0.000039\n",
       "15           PULocationID       0.0  0.000039  0.000039\n",
       "16           DOLocationID       0.0  0.000039  0.000039"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare %Missing column and %null column\n",
    "categorical_missing = {'Feature':[], 'Missing%':[], 'Null%':[], 'Total%':[]}\n",
    "for column in df.columns:\n",
    "    categorical_missing['Feature'].append(column)\n",
    "    categorical_missing['Missing%'].append(100*sum(df[column]=='Missing')/df.shape[0])\n",
    "    categorical_missing['Null%'].append(100*(df[column].isnull().sum())/df.shape[0])\n",
    "    categorical_missing['Total%'].append((100*sum(df[column]=='Missing')/df.shape[0])+(100*(df[column].isnull().sum())/df.shape[0]))\n",
    "pd.DataFrame(categorical_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b35c8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12867397</th>\n",
       "      <td>1</td>\n",
       "      <td>09/19/2016 12:28:38 {</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12867398</th>\n",
       "      <td>\"error\" : true</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12867399</th>\n",
       "      <td>\"message\" : \"Internal error\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12867400</th>\n",
       "      <td>\"status\" : 500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12867401</th>\n",
       "      <td>}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                VendorID   tpep_pickup_datetime  \\\n",
       "12867397                               1  09/19/2016 12:28:38 {   \n",
       "12867398                  \"error\" : true                    NaN   \n",
       "12867399    \"message\" : \"Internal error\"                    NaN   \n",
       "12867400                  \"status\" : 500                    NaN   \n",
       "12867401                               }                    NaN   \n",
       "\n",
       "         tpep_dropoff_datetime  passenger_count  trip_distance  RatecodeID  \\\n",
       "12867397                   NaN              NaN            NaN         NaN   \n",
       "12867398                   NaN              NaN            NaN         NaN   \n",
       "12867399                   NaN              NaN            NaN         NaN   \n",
       "12867400                   NaN              NaN            NaN         NaN   \n",
       "12867401                   NaN              NaN            NaN         NaN   \n",
       "\n",
       "         store_and_fwd_flag  payment_type  fare_amount  extra  mta_tax  \\\n",
       "12867397                NaN           NaN          NaN    NaN      NaN   \n",
       "12867398                NaN           NaN          NaN    NaN      NaN   \n",
       "12867399                NaN           NaN          NaN    NaN      NaN   \n",
       "12867400                NaN           NaN          NaN    NaN      NaN   \n",
       "12867401                NaN           NaN          NaN    NaN      NaN   \n",
       "\n",
       "          tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
       "12867397         NaN           NaN                    NaN           NaN   \n",
       "12867398         NaN           NaN                    NaN           NaN   \n",
       "12867399         NaN           NaN                    NaN           NaN   \n",
       "12867400         NaN           NaN                    NaN           NaN   \n",
       "12867401         NaN           NaN                    NaN           NaN   \n",
       "\n",
       "          PULocationID  DOLocationID  \n",
       "12867397           NaN           NaN  \n",
       "12867398           NaN           NaN  \n",
       "12867399           NaN           NaN  \n",
       "12867400           NaN           NaN  \n",
       "12867401           NaN           NaN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['PULocationID'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df539a2",
   "metadata": {},
   "source": [
    "From the above results, we can see that these lost almost all of data, so these should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f89c228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows = df[df['PULocationID'].isnull()]\n",
    "df = df.drop(null_rows.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff764764",
   "metadata": {},
   "source": [
    "- Check %Missing column and %null column again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b45f5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Missing%</th>\n",
       "      <th>Null%</th>\n",
       "      <th>Total%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VendorID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tpep_pickup_datetime</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tpep_dropoff_datetime</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RatecodeID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>store_and_fwd_flag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>payment_type</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fare_amount</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>extra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mta_tax</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tip_amount</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>improvement_surcharge</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>total_amount</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature  Missing%  Null%  Total%\n",
       "0                VendorID       0.0    0.0     0.0\n",
       "1    tpep_pickup_datetime       0.0    0.0     0.0\n",
       "2   tpep_dropoff_datetime       0.0    0.0     0.0\n",
       "3         passenger_count       0.0    0.0     0.0\n",
       "4           trip_distance       0.0    0.0     0.0\n",
       "5              RatecodeID       0.0    0.0     0.0\n",
       "6      store_and_fwd_flag       0.0    0.0     0.0\n",
       "7            payment_type       0.0    0.0     0.0\n",
       "8             fare_amount       0.0    0.0     0.0\n",
       "9                   extra       0.0    0.0     0.0\n",
       "10                mta_tax       0.0    0.0     0.0\n",
       "11             tip_amount       0.0    0.0     0.0\n",
       "12           tolls_amount       0.0    0.0     0.0\n",
       "13  improvement_surcharge       0.0    0.0     0.0\n",
       "14           total_amount       0.0    0.0     0.0\n",
       "15           PULocationID       0.0    0.0     0.0\n",
       "16           DOLocationID       0.0    0.0     0.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare %Missing column and %null column\n",
    "categorical_missing = {'Feature':[], 'Missing%':[], 'Null%':[], 'Total%':[]}\n",
    "for column in df.columns:\n",
    "    categorical_missing['Feature'].append(column)\n",
    "    categorical_missing['Missing%'].append(100*sum(df[column]=='Missing')/df.shape[0])\n",
    "    categorical_missing['Null%'].append(100*(df[column].isnull().sum())/df.shape[0])\n",
    "    categorical_missing['Total%'].append((100*sum(df[column]=='Missing')/df.shape[0])+(100*(df[column].isnull().sum())/df.shape[0]))\n",
    "pd.DataFrame(categorical_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3469dd5",
   "metadata": {},
   "source": [
    "### Selecting features："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c019876",
   "metadata": {},
   "source": [
    "- Look for rows and columns. Consider whether it makes sense to keep them or drop them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c32744",
   "metadata": {},
   "source": [
    "Feature Selection Summary:\n",
    "- VendorID: The identifier of the taxi provider or operator, the feature is obviously not useful for analysis. Drop the feature.\n",
    "- tpep_pickup_datetime: Retention year data\n",
    "- tpep_dropoff_datetime: Retention year data\n",
    "- passenger_count: Number of passengers, save.\n",
    "- trip_distance: Travel distance, save.\n",
    "- RatecodeID: Final rate code, drop it.\n",
    "- store_and_fwd_flag: Is a field in New York City taxi data that records a Boolean value indicating whether the trip was stored locally by the vehicle and subsequently forwarded to the dispatch center. The feature is obviously not useful for analysis. Drop the feature.\n",
    "- payment_type: The feature is obviously not useful for analysis. Drop the feature.\n",
    "- fare_amount: It is part of the total amount and is not helpful for analysis, drop.\n",
    "- extra: It is part of the total amount and is not helpful for analysis, drop.\n",
    "- mta_tax: It is part of the total amount and is not helpful for analysis, drop.\n",
    "- tip_amount: It is part of the total amount and is not helpful for analysis, drop.\n",
    "- tolls_amount: It is part of the total amount and is not helpful for analysis, drop.\n",
    "- improvement_surcharge: It is part of the total amount and is not helpful for analysis, drop.\n",
    "- total_amount: The total amount to be paid, save.\n",
    "- PULocationID: The location ID of the pick-up, save.\n",
    "- DOLocationID: The location ID of the drop-off, save."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132fd463",
   "metadata": {},
   "source": [
    "- Drop unselected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6cc344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"VendorID\", \"RatecodeID\", \"store_and_fwd_flag\", \"RatecodeID\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\",\n",
    "                  \"tolls_amount\", \"improvement_surcharge\"]\n",
    "df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc34a8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/12/2016 11:55:28 AM</td>\n",
       "      <td>08/12/2016 12:07:57 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>9.30</td>\n",
       "      <td>230.0</td>\n",
       "      <td>229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/20/2016 02:36:59 PM</td>\n",
       "      <td>07/20/2016 03:26:37 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.30</td>\n",
       "      <td>63.35</td>\n",
       "      <td>162.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07/05/2016 09:21:27 PM</td>\n",
       "      <td>07/05/2016 09:39:07 PM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>19.75</td>\n",
       "      <td>231.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/09/2016 11:39:16 PM</td>\n",
       "      <td>07/09/2016 11:44:16 PM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>6.30</td>\n",
       "      <td>186.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07/11/2016 10:42:40 PM</td>\n",
       "      <td>07/11/2016 10:52:42 PM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.30</td>\n",
       "      <td>161.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  \\\n",
       "0  08/12/2016 11:55:28 AM  08/12/2016 12:07:57 PM              1.0   \n",
       "1  07/20/2016 02:36:59 PM  07/20/2016 03:26:37 PM              1.0   \n",
       "2  07/05/2016 09:21:27 PM  07/05/2016 09:39:07 PM              2.0   \n",
       "3  07/09/2016 11:39:16 PM  07/09/2016 11:44:16 PM              1.0   \n",
       "4  07/11/2016 10:42:40 PM  07/11/2016 10:52:42 PM              5.0   \n",
       "\n",
       "   trip_distance  total_amount  PULocationID  DOLocationID  \n",
       "0           0.80          9.30         230.0         229.0  \n",
       "1          15.30         63.35         162.0         132.0  \n",
       "2           3.56         19.75         231.0         181.0  \n",
       "3           0.70          6.30         186.0         234.0  \n",
       "4           1.27          9.30         161.0         100.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea81ae49",
   "metadata": {},
   "source": [
    "- Clean up retained data.\n",
    "\n",
    "    Since we only need data within Manhattan, excluding data from non-Manhattan pick-up and drop-off locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4700f82",
   "metadata": {},
   "source": [
    "- Save updated/cleaned data frame to a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a57161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"programing data/2016_Yellow_Taxi_Trip_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d976482",
   "metadata": {},
   "source": [
    "- Saving the processed data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MySQL database connection\n",
    "conn = mysql.connector.connect(host='localhost', user='root', password='147258Xiao', database='Investment')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE Manhattan_ID (\n",
    "    tpep_pickup_datetime DATETIME,\n",
    "    tpep_dropoff_datetime DATETIME,\n",
    "    passenger_count INT,\n",
    "    trip_distance FLOAT,\n",
    "    PULocationID INT,\n",
    "    DOLocationID INT,\n",
    "    fare_amount FLOAT,\n",
    "    total_amount FLOAT \n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_table_sql)\n",
    "\n",
    "with open('programing data/2016_Yellow_Taxi_Trip_Data.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header line of the CSV file\n",
    "\n",
    "    for row in csv_reader:\n",
    "        \n",
    "        # Extract the data from the CSV file\n",
    "        tpep_pickup_datetime = datetime.strptime(row[0], '%m/%d/%Y %I:%M:%S %p')\n",
    "        tpep_dropoff_datetime = datetime.strptime(row[1], '%m/%d/%Y %I:%M:%S %p')\n",
    "        # Since there are very few missing values and the randomness of passengers is too strong, the number of passengers is filled with the lowest value (1).\n",
    "        passenger_count = int(float(row[2]))\n",
    "        trip_distance = float(row[3])\n",
    "        PULocationID = int(float(row[6]))\n",
    "        DOLocationID = int(float(row[7]))\n",
    "        fare_amount = float(row[4])\n",
    "        total_amount = float(row[5])\n",
    "\n",
    "        # Insert data into a database table\n",
    "        insert_query = \"INSERT INTO Investment.Taxi_2016 (tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, PULocationID, DOLocationID, fare_amount, total_amount) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        values = (tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, PULocationID, DOLocationID, fare_amount, total_amount)\n",
    "        cursor.execute(insert_query, values)\n",
    "        conn.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff07be8",
   "metadata": {},
   "source": [
    "- Summarize information: According to the LocationID summary information, the count of pick up, the count of drop off, the number of passengers of pick_up, the number of passengers of drop_off, the total cost of the number of passengers of pick_up, and the total cost of the number of passengers of drop_off in different regions are counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a44187",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Query pickup location statistics\n",
    "query_pickup = \"\"\"\n",
    "    SELECT \n",
    "        PULocationID,\n",
    "        COUNT(*) AS Pick_Up,\n",
    "        SUM(passenger_count) AS Pick_up_passenger,\n",
    "        SUM(fare_amount) AS Pick_up_fare\n",
    "    FROM \n",
    "        Taxi_2020\n",
    "    GROUP BY \n",
    "        PULocationID\n",
    "\"\"\"\n",
    "# Query drop-off location statistics\n",
    "query_dropoff = \"\"\"\n",
    "    SELECT \n",
    "        DOLocationID,\n",
    "        COUNT(*) AS Drop_Off,\n",
    "        SUM(passenger_count) AS Drop_off_passenger,\n",
    "        SUM(fare_amount) AS Drop_off_fare\n",
    "    FROM \n",
    "        Taxi_2020\n",
    "    GROUP BY \n",
    "        DOLocationID\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and get the results\n",
    "cursor.execute(query_pickup)\n",
    "df_pickup = cursor.fetchall()\n",
    "\n",
    "cursor.execute(query_dropoff)\n",
    "df_dropoff = cursor.fetchall()\n",
    "\n",
    "# Closing the database Connection\n",
    "conn.close()\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "df_pickup = pd.DataFrame(df_pickup, columns=['PULocationID', 'Pick_Up', 'Pick_up_passenger', 'Pick_up_fare'])\n",
    "df_dropoff = pd.DataFrame(df_dropoff, columns=['DOLocationID', 'Drop_Off', 'Drop_off_passenger', 'Drop_off_fare'])\n",
    "\n",
    "# Perform the association of pick-up and drop-off locations\n",
    "df_merged = pd.merge(df_pickup, df_dropoff, left_on='PULocationID', right_on='DOLocationID', how='inner')\n",
    "\n",
    "# Select the desired columns\n",
    "df_result = df_merged[['PULocationID', 'Pick_Up', 'Drop_Off', 'Pick_up_passenger', 'Drop_off_passenger', 'Pick_up_fare', 'Drop_off_fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca543caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('programing data/2016_Summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506c224",
   "metadata": {},
   "source": [
    "- Link database to create tables and insert information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f697b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MySQL database connection\n",
    "conn = mysql.connector.connect(host='localhost', user='root', password='147258Xiao', database='Investment')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE Taxi_Summary (\n",
    "    Year INT,\n",
    "    LocationID INT,\n",
    "    Pick_Up INT,\n",
    "    Drop_Off INT,\n",
    "    Pick_up_passenger INT,\n",
    "    Drop_off_passenger INT,\n",
    "    Pick_up_fare FLOAT,\n",
    "    Drop_off_fare FLOAT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('programing data/2016_Summary.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip the header line\n",
    "    for row in reader:\n",
    "        locationID = int(row[0])\n",
    "        pick_Up = row[1]\n",
    "        drop_Off = row[2]\n",
    "        pick_up_passenger = row[3]\n",
    "        drop_off_passenger = row[4]\n",
    "        pick_up_fare = row[5]\n",
    "        drop_off_fare = row[6]\n",
    "\n",
    "        # SQL statement to insert data\n",
    "        insert_sql = \"INSERT INTO Taxi_Summary (Year, LocationID, Pick_Up, Drop_Off, Pick_up_passenger, Drop_off_passenger, Pick_up_fare, Drop_off_fare) VALUES (2020, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        cursor.execute(insert_sql, (locationID, pick_Up, drop_Off, pick_up_passenger, drop_off_passenger, pick_up_fare, drop_off_fare))\n",
    "        conn.commit()\n",
    "        \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(host='localhost', user='root', password='147258Xiao', database='Investment')\n",
    "cursor = conn.cursor()\n",
    "query = \"SELECT * FROM Investment.Taxi_Summary\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df.to_csv('programing data/Taxi_Summary.csv', index=False, header=True)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2a629",
   "metadata": {},
   "source": [
    "### Data Standardization："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153357e",
   "metadata": {},
   "source": [
    "- Since the taxi data span and vary from year to year, Z-score is used to standardize the data.\n",
    "- Z-score normalization is a commonly used method for normalizing data by transforming the data into a standard normal distribution with mean 0 and standard deviation 1. This method makes the distribution of the data conform to the standard normal distribution in statistics, so that the data of different scales and ranges can be analyzed comparably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309c040b",
   "metadata": {},
   "source": [
    "- Loading the cleaned taxi data and the taxi zone data\n",
    "- Removing data that is not in the Manhattan area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25c1efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('programing data/Taxi_Summary.csv')\n",
    "zone = pd.read_csv('programing data/taxi_zones.csv')\n",
    "location_ids = zone['LocationID'].tolist()\n",
    "df = df[df['LocationID'].isin(location_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad41a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = ['Pick_Up', 'Drop_Off', 'Pick_up_passenger', 'Drop_off_passenger', 'Pick_up_fare', 'Drop_off_fare']\n",
    "\n",
    "# Create a new DataFrame to hold the normalized data\n",
    "df_normalized = pd.DataFrame()\n",
    "\n",
    "# The YEAR and LocationID columns are extracted from the raw data\n",
    "df_normalized['Year'] = df['Year']\n",
    "df_normalized['LocationID'] = df['LocationID']\n",
    "\n",
    "# Calculate the mean and standard deviation\n",
    "mean = df[columns_to_normalize].mean()\n",
    "std = df[columns_to_normalize].std()\n",
    "\n",
    "# Z-score normalization is used\n",
    "for column in columns_to_normalize:\n",
    "    df_normalized[column] = (df[column] - mean[column]) / std[column]\n",
    "\n",
    "# Remerge the normalized data with YEAR and LocationID\n",
    "df_normalized = df_normalized.merge(df[['Year', 'LocationID']], on=['Year', 'LocationID'], how='left')\n",
    "\n",
    "# Output the normalized data\n",
    "df_normalized.to_csv('programing data/Summary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56b3c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/ybj4cz9s1wd3hg435tvgpfb00000gn/T/ipykernel_17313/3158276885.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_estate = pd.read_csv('programing data/Real_Estate.csv')\n"
     ]
    }
   ],
   "source": [
    "df_normalized = pd.read_csv('programing data/Summary.csv')\n",
    "df_normalized = df_normalized[~((df_normalized['Year'] == 2020))]\n",
    "df_normalized = df_normalized.rename(columns = {'Year':'YEAR'})\n",
    "df_estate = pd.read_csv('programing data/Real_Estate.csv')\n",
    "df_estate = df_estate[~((df_estate['YEAR'] == 2014))]\n",
    "df_estate['YEAR'] = df_estate['YEAR'].astype(int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e5918de",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_normalized, df_estate, on=['YEAR', 'LocationID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5286bc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  AVTOT   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     203.3\n",
      "Date:                Mon, 03 Jul 2023   Prob (F-statistic):          4.72e-260\n",
      "Time:                        20:04:38   Log-Likelihood:            -1.0969e+07\n",
      "No. Observations:              615778   AIC:                         2.194e+07\n",
      "Df Residuals:                  615771   BIC:                         2.194e+07\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const               1.176e+06   1.88e+04     62.442      0.000    1.14e+06    1.21e+06\n",
      "Pick_Up            -8.506e+06   1.46e+06     -5.824      0.000   -1.14e+07   -5.64e+06\n",
      "Drop_Off            7.991e+06   1.42e+06      5.641      0.000    5.21e+06    1.08e+07\n",
      "Pick_up_passenger   6.839e+06   1.51e+06      4.524      0.000    3.88e+06     9.8e+06\n",
      "Drop_off_passenger -8.845e+06   1.47e+06     -6.029      0.000   -1.17e+07   -5.97e+06\n",
      "Pick_up_fare         2.81e+06   2.33e+05     12.050      0.000    2.35e+06    3.27e+06\n",
      "Drop_off_fare       1.056e+05   1.95e+05      0.541      0.588   -2.77e+05    4.88e+05\n",
      "==============================================================================\n",
      "Omnibus:                  2572331.728   Durbin-Watson:                   1.819\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):   16817937373428.588\n",
      "Skew:                         117.206   Prob(JB):                         0.00\n",
      "Kurtosis:                   25604.281   Cond. No.                         499.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = merged_df[['Pick_Up', 'Drop_Off', 'Pick_up_passenger', 'Drop_off_passenger', 'Pick_up_fare', 'Drop_off_fare']]\n",
    "y = merged_df['AVTOT']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4db6be",
   "metadata": {},
   "source": [
    "- Conclusion: The relationship between taxi data and real estate data is weak, and the prediction model cannot be generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd21d00",
   "metadata": {},
   "source": [
    "- The taxi data is incomplete\n",
    "    2016/7/1-2016/12/31\n",
    "    2017/3/30-2017/12/31\n",
    "    2018/2/14-2018/12/31\n",
    "    2019/6/11-2019/12/31\n",
    "    2020/1/1-2020/12/31\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970149fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
